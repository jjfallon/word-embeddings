{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# doc2vec with gensim\n",
    "\n",
    "This notebook demonstrates the basic commands needed to train a doc2vec model using the functions provided by gensim by working through a toy example. Here python 2.7 and gensim version 2.2.0 are used.\n",
    "\n",
    "doc2vec is an extension of word2vec which converts documents (these could be any sequences of words â€“ paragraphs, comments, or even whole documents). This notebook only demonstrates how to use the technique; it does not explain how it works. For details consult the paper by Le and Mikolov: https://arxiv.org/abs/1405.4053."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Documents to vectors\n",
    "In this first section we will show how to produce a vector for each document. First load the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Define helper functions\n",
    "Next we need to define a couple of helper functions. One which splits ('tokenises') a string into a list of words, and one which takes puts our data into the data structure gensim is expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Tokenise on whitespace\n",
    "def tokeniser(text):\n",
    "    return re.findall(r\"\\S+\", text)\n",
    "\n",
    "# Create labelled sentence data structure\n",
    "def labeller_id(ID, text):\n",
    "    return TaggedDocument(tokeniser(text), [ID])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's see what the tokeniser does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an', 'example', 'string', 'of', 'text']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokeniser('an example string of text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is a very simple tokeniser, much more advanced ones are available. \n",
    "\n",
    "Doc2vec expects data in the 'TaggedDocument' format, which is a list of words within the documents and a list of IDs. In this case we are creating one vector per document so each document needs one, unique ID. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['an', 'example', 'document'], tags=['doc1'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_document = 'an example document'\n",
    "ex_id = 'doc1'\n",
    "labeller_id(ex_id, ex_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Getting data into the right format\n",
    "Let's consider the example where we have text within a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create example data\n",
    "df = pd.DataFrame()\n",
    "df['text'] = [\n",
    "                'this is text', \n",
    "                'any more text?', \n",
    "                'even more text!', \n",
    "                'words, all words'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can use the dataframe IDs as the document IDs and convert all the documents into the required TaggedDocument format. If there is a column with unique IDs, this column could be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([TaggedDocument(words=['this', 'is', 'text'], tags=[0]),\n",
       "       TaggedDocument(words=['any', 'more', 'text?'], tags=[1]),\n",
       "       TaggedDocument(words=['even', 'more', 'text!'], tags=[2]),\n",
       "       TaggedDocument(words=['words,', 'all', 'words'], tags=[3])], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data into correct format\n",
    "documents =  df.apply(lambda x: labeller_id(x.name, x['text']), axis=1).values\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build the model\n",
    "Now we can build the doc2vec model and then delete some of the items created by gensim during the model build in order to free up memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = Doc2Vec(documents = documents,\n",
    "        size = 5,\n",
    "        seed = 40,\n",
    "        min_count = 0,\n",
    "        max_vocab_size = None,\n",
    "        window =2,\n",
    "        iter = 5)\n",
    "\n",
    "# Free up memory\n",
    "model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can retrieve the vectors produced for each of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00165228],\n",
       "       [ 0.28662241],\n",
       "       [ 0.3524237 ],\n",
       "       [ 0.39406374]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.doctag_syn0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "or we can retrieve documents by specifying the ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.28662241], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If strings had been used for IDs the command model.docvecs.doctags.keys() could be used to retrieve these strings, but this command does not necessarily return them in the same order as doctag_syn0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Using the model\n",
    "Vectors for new documents can be inferred:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.49406224], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentence = ['one', 'more', 'sentence']\n",
    "model.infer_vector(new_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As can the vectors for multiple sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.15742688],\n",
       "        [ 0.02989352]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentences = [ ['first', 'text'], ['second', 'test']]\n",
    "np.matrix(map(model.infer_vector, new_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can also get the most similiar documents to a new document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1.0)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'any more text?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text = \"any old text\"\n",
    "new_vector = model.infer_vector(tokeniser(new_text))\n",
    "similar = model.docvecs.most_similar([new_vector], topn=1)\n",
    "\n",
    "# Print the closest tag and the similarity score\n",
    "print similar\n",
    "\n",
    "# Print the text\n",
    "df.loc[similar[0][0], 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caution: inferring vectors for training documents\n",
    "\n",
    "When given a document used to train the model the infer_vectors function is not guaranteed to return the same vector as that associated with the document in the model itself. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model vector for document 0:\n",
      "[-0.00165228]\n",
      "Inferred vector for document 0:\n",
      "[-0.35209045]\n"
     ]
    }
   ],
   "source": [
    "print \"Model vector for document 0:\"\n",
    "print model.docvecs[0]\n",
    "print \"Inferred vector for document 0:\"\n",
    "print model.infer_vector( tokeniser(df.loc[0,'text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is safer to explictly retrieve the vectors for documents that were used to train the model. Modelling tuning should help to reduce this discrepancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Topics to vectors\n",
    "\n",
    "Another way in which doc2vec can be used is to learn vectors for topics rather than for individual documents. To do this instead of giving the model a unique ID for each document you instead pass a list of topics. Each document can have multiple topics.\n",
    "\n",
    "Let's demonstrate. First we need to tweak our labeller function so that it takes a list as input rather than a single ID. This reuses the tokeniser function defined previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create labelled sentence data structure when given topic list\n",
    "def labeller_topics(topic_list, text):\n",
    "    return TaggedDocument(tokeniser(text), topic_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Next define some example data where there are two topics: 'question' and 'cats'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is there any more text?</td>\n",
       "      <td>[question]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>where are the words of the documents</td>\n",
       "      <td>[question]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cats like to chase mice</td>\n",
       "      <td>[cats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cats do not like dogs</td>\n",
       "      <td>[cats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you like cats?</td>\n",
       "      <td>[question, cats]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text             topic\n",
       "0               is there any more text?        [question]\n",
       "1  where are the words of the documents        [question]\n",
       "2               cats like to chase mice            [cats]\n",
       "3                 cats do not like dogs            [cats]\n",
       "4                     do you like cats?  [question, cats]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create example data\n",
    "df2 = pd.DataFrame()\n",
    "df2['text'] = [\n",
    "    'is there any more text?',\n",
    "    'where are the words of the documents',\n",
    "    'cats like to chase mice',\n",
    "    'cats do not like dogs',\n",
    "    'do you like cats?'\n",
    "    ]\n",
    "\n",
    "# Each document can have multiple topics associated with it (list of topics per document)\n",
    "df2['topic'] = [\n",
    "    ['question'],\n",
    "    ['question'],\n",
    "    ['cats'],\n",
    "    ['cats'],\n",
    "    ['question', 'cats']\n",
    "    ]\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This can be converted into TaggedDocument form using the new labeller_topics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "documents2 = df2.apply(lambda x: labeller_topics(x['topic'], x['text']), axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then a doc2vec model can be build as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "model2 = Doc2Vec(documents = documents2,\n",
    "        size = 2,\n",
    "        seed = 42,\n",
    "        min_count = 1,\n",
    "        max_vocab_size = None,\n",
    "        window = 5,\n",
    "        iter = 5)\n",
    "\n",
    "# Free up memory\n",
    "model2.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's look at the document vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03462205, -0.05810256],\n",
       "       [ 0.10018398,  0.24293993]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.docvecs.doctag_syn0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "and note only two vectors have been produced. This is encouraging as we only had two topics. Checking the tags of these vectors gives the two topics we were expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats', 'question']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.docvecs.doctags.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note, the command above returns all the topics but the order does not necessarily correspond to the order of the vectors in doctag_syn0. For example, the command above returns 'cats' as the first topic but if we look at the 'cats' vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10018398,  0.24293993], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.docvecs['cats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "we see it is the second vector in the doctag_syn0 array not the first. The safest way to retrieve a list of topics and their vectors in the correct order is to explictly retrieve them by name. For example, if we wanted a dataframe containing topics and their vectors we could do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cats</td>\n",
       "      <td>[0.100184, 0.24294]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>question</td>\n",
       "      <td>[-0.034622, -0.0581026]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topics                  vectors\n",
       "0      cats      [0.100184, 0.24294]\n",
       "1  question  [-0.034622, -0.0581026]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics = pd.DataFrame()\n",
    "\n",
    "# Store the topics\n",
    "df_topics['topics'] = model2.docvecs.doctags.keys()\n",
    "\n",
    "# Explictly retrieve the vectors\n",
    "df_topics['vectors'] = df_topics['topics'].apply(lambda x: model2.docvecs[x])\n",
    "df_topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
